{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fines for providers in nursing homes\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we are working with nursing home inspection data from the United States to try to predict which providers may be fined and for how much. We are going to use scikit-learn Python package to construct construct our machine learning models.\n",
    "\n",
    "\n",
    "## Downloading the data\n",
    "\n",
    "We can download the data set from Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-12-27 01:12:49--  http://dataincubator-wqu.s3.amazonaws.com/mldata/providers-train.csv\n",
      "Resolving dataincubator-wqu.s3.amazonaws.com (dataincubator-wqu.s3.amazonaws.com)... 52.217.95.193\n",
      "Connecting to dataincubator-wqu.s3.amazonaws.com (dataincubator-wqu.s3.amazonaws.com)|52.217.95.193|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3398120 (3.2M) [text/csv]\n",
      "Saving to: ‘./ml-data/providers-train.csv’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  209K 16s\n",
      "    50K .......... .......... .......... .......... ..........  3%  442K 11s\n",
      "   100K .......... .......... .......... .......... ..........  4% 1.29M 8s\n",
      "   150K .......... .......... .......... .......... ..........  6% 1.25M 7s\n",
      "   200K .......... .......... .......... .......... ..........  7%  745K 6s\n",
      "   250K .......... .......... .......... .......... ..........  9% 1.26M 5s\n",
      "   300K .......... .......... .......... .......... .......... 10% 1.29M 5s\n",
      "   350K .......... .......... .......... .......... .......... 12% 1.24M 4s\n",
      "   400K .......... .......... .......... .......... .......... 13% 1.30M 4s\n",
      "   450K .......... .......... .......... .......... .......... 15% 1.25M 4s\n",
      "   500K .......... .......... .......... .......... .......... 16% 1.28M 4s\n",
      "   550K .......... .......... .......... .......... .......... 18% 1.26M 3s\n",
      "   600K .......... .......... .......... .......... .......... 19% 1.26M 3s\n",
      "   650K .......... .......... .......... .......... .......... 21% 1.28M 3s\n",
      "   700K .......... .......... .......... .......... .......... 22% 1.25M 3s\n",
      "   750K .......... .......... .......... .......... .......... 24% 1.30M 3s\n",
      "   800K .......... .......... .......... .......... .......... 25% 1.25M 3s\n",
      "   850K .......... .......... .......... .......... .......... 27% 1.30M 3s\n",
      "   900K .......... .......... .......... .......... .......... 28% 1.24M 3s\n",
      "   950K .......... .......... .......... .......... .......... 30% 1.26M 2s\n",
      "  1000K .......... .......... .......... .......... .......... 31% 1.29M 2s\n",
      "  1050K .......... .......... .......... .......... .......... 33% 1.25M 2s\n",
      "  1100K .......... .......... .......... .......... .......... 34% 1.28M 2s\n",
      "  1150K .......... .......... .......... .......... .......... 36% 1.26M 2s\n",
      "  1200K .......... .......... .......... .......... .......... 37% 1.29M 2s\n",
      "  1250K .......... .......... .......... .......... .......... 39%  792K 2s\n",
      "  1300K .......... .......... .......... .......... .......... 40% 1.56M 2s\n",
      "  1350K .......... .......... .......... .......... .......... 42% 2.28M 2s\n",
      "  1400K .......... .......... .......... .......... .......... 43%  790K 2s\n",
      "  1450K .......... .......... .......... .......... .......... 45% 3.51M 2s\n",
      "  1500K .......... .......... .......... .......... .......... 46% 1.26M 2s\n",
      "  1550K .......... .......... .......... .......... .......... 48% 1.27M 2s\n",
      "  1600K .......... .......... .......... .......... .......... 49% 1.27M 2s\n",
      "  1650K .......... .......... .......... .......... .......... 51% 1.25M 2s\n",
      "  1700K .......... .......... .......... .......... .......... 52% 1.08M 1s\n",
      "  1750K .......... .......... .......... .......... .......... 54% 1.56M 1s\n",
      "  1800K .......... .......... .......... .......... .......... 55% 1.23M 1s\n",
      "  1850K .......... .......... .......... .......... .......... 57% 1.31M 1s\n",
      "  1900K .......... .......... .......... .......... .......... 58%  355K 1s\n",
      "  1950K .......... .......... .......... .......... .......... 60% 5.20M 1s\n",
      "  2000K .......... .......... .......... .......... .......... 61% 5.39M 1s\n",
      "  2050K .......... .......... .......... .......... .......... 63% 10.2M 1s\n",
      "  2100K .......... .......... .......... .......... .......... 64%  366K 1s\n",
      "  2150K .......... .......... .......... .......... .......... 66% 7.46M 1s\n",
      "  2200K .......... .......... .......... .......... .......... 67% 6.86M 1s\n",
      "  2250K .......... .......... .......... .......... .......... 69% 1.07M 1s\n",
      "  2300K .......... .......... .......... .......... .......... 70% 4.46M 1s\n",
      "  2350K .......... .......... .......... .......... .......... 72%  607K 1s\n",
      "  2400K .......... .......... .......... .......... .......... 73% 7.16M 1s\n",
      "  2450K .......... .......... .......... .......... .......... 75% 8.34M 1s\n",
      "  2500K .......... .......... .......... .......... .......... 76%  411K 1s\n",
      "  2550K .......... .......... .......... .......... .......... 78% 2.00M 1s\n",
      "  2600K .......... .......... .......... .......... .......... 79% 2.63M 1s\n",
      "  2650K .......... .......... .......... .......... .......... 81% 6.71M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 82% 1.88M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 84% 1.70M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 85% 1.25M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 87% 1.26M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 88% 1.25M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 90% 1.28M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 91% 1.26M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 93% 1.22M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 94% 1.30M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 96% 1.25M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 97% 1.29M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 99% 1.25M 0s\n",
      "  3300K .......... ........                                   100% 1.32M=2.9s\n",
      "\n",
      "2021-12-27 01:12:52 (1.13 MB/s) - ‘./ml-data/providers-train.csv’ saved [3398120/3398120]\n",
      "\n",
      "--2021-12-27 01:12:52--  http://dataincubator-wqu.s3.amazonaws.com/mldata/providers-metadata.csv\n",
      "Resolving dataincubator-wqu.s3.amazonaws.com (dataincubator-wqu.s3.amazonaws.com)... 52.216.78.44\n",
      "Connecting to dataincubator-wqu.s3.amazonaws.com (dataincubator-wqu.s3.amazonaws.com)|52.216.78.44|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9401 (9.2K) [text/csv]\n",
      "Saving to: ‘./ml-data/providers-metadata.csv’\n",
      "\n",
      "     0K .........                                             100% 1.34M=0.007s\n",
      "\n",
      "2021-12-27 01:12:52 (1.34 MB/s) - ‘./ml-data/providers-metadata.csv’ saved [9401/9401]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir data\n",
    "wget http://dataincubator-wqu.s3.amazonaws.com/mldata/providers-train.csv -nc -P ./ml-data\n",
    "wget http://dataincubator-wqu.s3.amazonaws.com/mldata/providers-metadata.csv -nc -P ./ml-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Label</th>\n",
       "      <th>Description</th>\n",
       "      <th>Format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROVNUM</td>\n",
       "      <td>Federal Provider Number</td>\n",
       "      <td>Federal Provider Number</td>\n",
       "      <td>6 alphanumeric characters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROVNAME</td>\n",
       "      <td>Provider Name</td>\n",
       "      <td>Provider Name</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>Provider Address</td>\n",
       "      <td>Provider Address</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CITY</td>\n",
       "      <td>Provider City</td>\n",
       "      <td>Provider City</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STATE</td>\n",
       "      <td>Provider State</td>\n",
       "      <td>Provider State</td>\n",
       "      <td>2-character postal abbreviation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable                    Label              Description  \\\n",
       "0   PROVNUM  Federal Provider Number  Federal Provider Number   \n",
       "1  PROVNAME            Provider Name            Provider Name   \n",
       "2   ADDRESS         Provider Address         Provider Address   \n",
       "3      CITY            Provider City            Provider City   \n",
       "4     STATE           Provider State           Provider State   \n",
       "\n",
       "                            Format  \n",
       "0        6 alphanumeric characters  \n",
       "1                             text  \n",
       "2                             text  \n",
       "3                             text  \n",
       "4  2-character postal abbreviation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('./ml-data/providers-metadata.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./ml-data/providers-train.csv', encoding='latin1')\n",
    "\n",
    "fine_counts = data.pop('FINE_CNT')\n",
    "fine_totals = data.pop('FINE_TOT')\n",
    "cycle_2_score = data.pop('CYCLE_2_TOTAL_SCORE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A federal agency, Centers for Medicare and Medicaid Services (CMS), imposes regulations on nursing homes. However, nursing homes are inspected by state agencies for compliance with regulations, and fines for violations can vary widely between states.\n",
    "\n",
    "Let's develop a very simple initial model to predict the amount of fines a nursing home might expect to pay based on its location. Fill in the class definition of the custom estimator, `StateMeanEstimator`, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "\n",
    "class GroupMeanEstimator(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, grouper):\n",
    "        self.grouper = grouper\n",
    "        self.group_averages = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if not isinstance(X,pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        # Use self.group_averages to store the average penalty by group\n",
    "        self.group_averages = y.groupby(X[self.grouper]).mean().to_dict()\n",
    "        self.group_averages['global_average'] = y.mean()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not isinstance(X,pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        # Return a list of predicted penalties based on group of samples in X\n",
    "        return [self.group_averages.get(group, self.group_averages['global_average']) for group in X[self.grouper]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filling in class definition, we can create an instance of the estimator and fit it to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sme', GroupMeanEstimator(grouper='STATE'))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "state_model = Pipeline([\n",
    "    ('sme', GroupMeanEstimator(grouper='STATE'))\n",
    "    ])\n",
    "state_model.fit(data, fine_totals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we should test that our predict method works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8438.121359223302,\n",
       " 9216.964686998395,\n",
       " 8054.977611940299,\n",
       " 8214.822977725675,\n",
       " 16612.338211382114]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_model.predict(data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, what if we have data from a nursing home in a state (or territory) of the US which is not in the training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14969.857687877915]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_model.predict(pd.DataFrame([{'STATE': 'AS'}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nursing homes vary greatly in their business characteristics. Some are owned by the government or non-profits while others are run for profit. Some house a few dozen residents while others house hundreds. Some are located within hospitals and may work with more vulnerable populations. We will try to predict which facilities are fined based on their business characteristics.\n",
    "\n",
    "We'll begin with columns in our DataFrame containing numeric and boolean features. Some of the rows contain null values; estimators cannot handle null values so these must be imputed or dropped. We will create a `Pipeline` containing transformers that process these features, followed by an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "simple_cols = ['BEDCERT', 'RESTOT', 'INHOSP', 'CCRC_FACIL', 'SFF', 'CHOW_LAST_12MOS', 'SPRINKLER_STATUS', 'EXP_TOTAL', 'ADJ_TOTAL']\n",
    "\n",
    "class ColumnSelectTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        return X[self.columns]\n",
    "        \n",
    "simple_features = Pipeline([\n",
    "    ('cst', ColumnSelectTransformer(simple_cols)),\n",
    "    ('imputer', SimpleImputer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estimator__n_estimators': 20, 'estimator__max_depth': 4}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "param_grid = {'estimator__n_estimators': range(20, 100, 10),\n",
    "              'estimator__max_depth': range(3, 15, 1)}\n",
    "\n",
    "simple_features_model = Pipeline([\n",
    "    ('simple', simple_features),\n",
    "    ('estimator', RandomForestClassifier(n_estimators=60, max_depth = 5))\n",
    "])\n",
    "\n",
    "gs = RandomizedSearchCV(simple_features_model, param_distributions = param_grid, cv = 5, n_iter = 50, n_jobs = 4, verbose = 1)\n",
    "\n",
    "gs.fit(data, fine_counts > 0)\n",
    "\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('simple',\n",
       "                 Pipeline(steps=[('cst',\n",
       "                                  ColumnSelectTransformer(columns=['BEDCERT',\n",
       "                                                                   'RESTOT',\n",
       "                                                                   'INHOSP',\n",
       "                                                                   'CCRC_FACIL',\n",
       "                                                                   'SFF',\n",
       "                                                                   'CHOW_LAST_12MOS',\n",
       "                                                                   'SPRINKLER_STATUS',\n",
       "                                                                   'EXP_TOTAL',\n",
       "                                                                   'ADJ_TOTAL'])),\n",
       "                                 ('imputer', SimpleImputer())])),\n",
       "                ('estimator',\n",
       "                 RandomForestClassifier(min_samples_leaf=100,\n",
       "                                        n_estimators=200))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_features_model = Pipeline([\n",
    "    ('simple', simple_features),\n",
    "    ('estimator', RandomForestClassifier(n_estimators=200, min_samples_leaf = 100))\n",
    "])\n",
    "\n",
    "simple_features_model.fit(data, fine_counts > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_probability(model):\n",
    "    def predict_proba(X):\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "    return predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'OWNERSHIP'` and `'CERTIFICATION'` columns contain categorical data. We will have to encode the categorical data into numerical features before we pass them to an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "owner_onehot = Pipeline([\n",
    "    ('cst', ColumnSelectTransformer(['OWNERSHIP'])),\n",
    "    ('ohe', OneHotEncoder (categories = 'auto', sparse = False))\n",
    "])\n",
    "\n",
    "cert_onehot = Pipeline([\n",
    "    ('cst', ColumnSelectTransformer(['CERTIFICATION'])),\n",
    "    ('ohe', OneHotEncoder (categories = 'auto', sparse = False))\n",
    "])\n",
    "\n",
    "categorical_features = FeatureUnion([\n",
    "    ('owner', owner_onehot),\n",
    "    ('cert', cert_onehot)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_model = Pipeline([\n",
    "    ('categorical', categorical_features),\n",
    "    ('estimator', RandomForestClassifier(n_estimators=200, min_samples_leaf = 100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('categorical',\n",
       "                 FeatureUnion(transformer_list=[('owner',\n",
       "                                                 Pipeline(steps=[('cst',\n",
       "                                                                  ColumnSelectTransformer(columns=['OWNERSHIP'])),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OneHotEncoder(sparse=False))])),\n",
       "                                                ('cert',\n",
       "                                                 Pipeline(steps=[('cst',\n",
       "                                                                  ColumnSelectTransformer(columns=['CERTIFICATION'])),\n",
       "                                                                 ('ohe',\n",
       "                                                                  OneHotEncoder(sparse=False))]))])),\n",
       "                ('estimator',\n",
       "                 RandomForestClassifier(min_samples_leaf=100,\n",
       "                                        n_estimators=200))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features_model.fit(data, fine_counts > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll combine `simple_features` and `categorical_features` in a `FeatureUnion`, followed by an estimator in a `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing  import PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_features = FeatureUnion([\n",
    "    ('simple', simple_features),\n",
    "    ('categorical', categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_model = Pipeline([\n",
    "    ('features', business_features),\n",
    "    ('ploy', PolynomialFeatures(3)),\n",
    "    ('estimator', RandomForestClassifier(n_estimators=200, min_samples_leaf = 100))\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('simple',\n",
       "                                                 Pipeline(steps=[('cst',\n",
       "                                                                  ColumnSelectTransformer(columns=['BEDCERT',\n",
       "                                                                                                   'RESTOT',\n",
       "                                                                                                   'INHOSP',\n",
       "                                                                                                   'CCRC_FACIL',\n",
       "                                                                                                   'SFF',\n",
       "                                                                                                   'CHOW_LAST_12MOS',\n",
       "                                                                                                   'SPRINKLER_STATUS',\n",
       "                                                                                                   'EXP_TOTAL',\n",
       "                                                                                                   'ADJ_TOTAL'])),\n",
       "                                                                 ('imputer',\n",
       "                                                                  SimpleImputer())])),\n",
       "                                                ('categorical',\n",
       "                                                 FeatureUnion(transformer_list=[('owner',\n",
       "                                                                                 Pipeline(steps=[('cst',\n",
       "                                                                                                  ColumnSelectTransformer(columns=['OWNERSHIP'])),\n",
       "                                                                                                 ('ohe',\n",
       "                                                                                                  OneHotEncoder(sparse=False))])),\n",
       "                                                                                ('cert',\n",
       "                                                                                 Pipeline(steps=[('cst',\n",
       "                                                                                                  ColumnSelectTransformer(columns=['CERTIFICATION'])),\n",
       "                                                                                                 ('ohe',\n",
       "                                                                                                  OneHotEncoder(sparse=False))]))]))])),\n",
       "                ('ploy', PolynomialFeatures(degree=3)),\n",
       "                ('estimator',\n",
       "                 RandomForestClassifier(min_samples_leaf=100,\n",
       "                                        n_estimators=200))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_model.fit(data, fine_counts > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surveys reveal safety and health deficiencies at nursing homes that may indicate risk for incidents (and penalties). CMS routinely makes surveys of nursing homes. Build a model that combines the `business_features` of each facility with its cycle 1 survey results, as well as the time between the cycle 1 and cycle 2 survey to predict the cycle 2 total score.\n",
    "\n",
    "First, let's create a transformer to calculate the difference in time between the cycle 1 and cycle 2 surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimedeltaTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, t1_col, t2_col):\n",
    "        self.t1_col = t1_col\n",
    "        self.t2_col = t2_col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not isinstance(X,pd.DataFrame):\n",
    "               X = pd.DataFrame(X)\n",
    "        return (pd.to_datetime( X[self.t2_col])\n",
    "                -pd.to_datetime( X[self.t1_col])).values.reshape(-1,1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_date = 'CYCLE_1_SURVEY_DATE'\n",
    "cycle_2_date = 'CYCLE_2_SURVEY_DATE'\n",
    "time_feature = TimedeltaTransformer(cycle_1_date, cycle_2_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we'll collect the cycle 1 survey features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_1_cols = ['CYCLE_1_DEFS', 'CYCLE_1_NFROMDEFS', 'CYCLE_1_NFROMCOMP',\n",
    "                'CYCLE_1_DEFS_SCORE', 'CYCLE_1_NUMREVIS',\n",
    "                'CYCLE_1_REVISIT_SCORE', 'CYCLE_1_TOTAL_SCORE']\n",
    "cycle_1_features = ColumnSelectTransformer(cycle_1_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "survey_model = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('business', business_features),\n",
    "        ('survey', cycle_1_features),\n",
    "        ('time', time_feature)\n",
    "    ])),\n",
    "    (\"poly\", PolynomialFeatures(2)),\n",
    "    (\"svd\", TruncatedSVD(20) ),\n",
    "    (\"classifier\", RandomForestRegressor(n_estimators=200, min_samples_leaf = 100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('business',\n",
       "                                                 FeatureUnion(transformer_list=[('simple',\n",
       "                                                                                 Pipeline(steps=[('cst',\n",
       "                                                                                                  ColumnSelectTransformer(columns=['BEDCERT',\n",
       "                                                                                                                                   'RESTOT',\n",
       "                                                                                                                                   'INHOSP',\n",
       "                                                                                                                                   'CCRC_FACIL',\n",
       "                                                                                                                                   'SFF',\n",
       "                                                                                                                                   'CHOW_LAST_12MOS',\n",
       "                                                                                                                                   'SPRINKLER_STATUS',\n",
       "                                                                                                                                   'EXP_TOTAL',\n",
       "                                                                                                                                   'ADJ_TOTAL'])),\n",
       "                                                                                                 ('imputer',\n",
       "                                                                                                  SimpleImputer())])),\n",
       "                                                                                ('categorical',\n",
       "                                                                                 FeatureUnion(transformer_...\n",
       "                                                                                  'CYCLE_1_NFROMDEFS',\n",
       "                                                                                  'CYCLE_1_NFROMCOMP',\n",
       "                                                                                  'CYCLE_1_DEFS_SCORE',\n",
       "                                                                                  'CYCLE_1_NUMREVIS',\n",
       "                                                                                  'CYCLE_1_REVISIT_SCORE',\n",
       "                                                                                  'CYCLE_1_TOTAL_SCORE'])),\n",
       "                                                ('time',\n",
       "                                                 TimedeltaTransformer(t1_col='CYCLE_1_SURVEY_DATE',\n",
       "                                                                      t2_col='CYCLE_2_SURVEY_DATE'))])),\n",
       "                ('poly', PolynomialFeatures()),\n",
       "                ('svd', TruncatedSVD(n_components=20)),\n",
       "                ('classifier',\n",
       "                 RandomForestRegressor(min_samples_leaf=100,\n",
       "                                       n_estimators=200))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survey_model.fit(data, cycle_2_score.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2021 WorldQuant University. This content is licensed solely for personal use. Redistribution or publication of this material is strictly prohibited.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
